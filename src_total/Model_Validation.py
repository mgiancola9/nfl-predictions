import xgboost as xgb
import preprocess_chrono_weekly as preprocess
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_absolute_error, mean_squared_error
import os

# ==============================================================================
# CONFIGURATION
# ==============================================================================
# The master file generated by pull_data.py
MASTER_DATA_FILE = "games_2016_2025.csv" 

# Validation Strategy: Train on history, test on recent/current seasons
TEST_SEASONS = [2024, 2025] 

FEATURE_COLUMNS = [
    'total_line', 'spread_line', 'week', 'weather_temp', 'weather_wind_mph',
    'away_rest', 'home_rest',
    
    # Efficiency Features
    'away_avg_passing_epa', 'home_avg_passing_epa_allowed',
    'away_avg_rushing_epa', 'home_avg_rushing_epa_allowed',
    'home_avg_passing_epa', 'away_avg_passing_epa_allowed',
    'home_avg_rushing_epa', 'away_avg_rushing_epa_allowed',
    
    # Scoring Features
    'away_avg_points_scored', 'home_avg_points_allowed',
    'home_avg_points_scored', 'away_avg_points_allowed',
]

    # --- NEW PACE FEATURES ---
    # How fast does the Away team play? vs How fast does Home defense force you to play?
#    'away_avg_plays', 'home_avg_plays_allowed',
#    'home_avg_plays', 'away_avg_plays_allowed'
#]

TARGET_COL = 'actual_total'

def run_validation_suite():
    print("--- STARTING VALIDATION SUITE ---")
    
    # 1. LOAD MASTER DATA
    print(f"Loading and enriching {MASTER_DATA_FILE}...")
    full_data = preprocess.merge_data(MASTER_DATA_FILE)
    
    # Calculate Target
    full_data[TARGET_COL] = full_data['home_score'] + full_data['away_score']
    
    # Filter out games that haven't happened yet
    valid_data = full_data.dropna(subset=[TARGET_COL])
    
    print(f"Total Completed Games with Data: {len(valid_data)}")

    # 2. DYNAMIC TRAIN/TEST SPLIT
    train_df = valid_data[~valid_data['season'].isin(TEST_SEASONS)].copy()
    test_df = valid_data[valid_data['season'].isin(TEST_SEASONS)].copy()
    
    print(f"Training Set (2016-{min(TEST_SEASONS)-1}): {len(train_df)} games")
    print(f"Testing Set ({min(TEST_SEASONS)}-{max(TEST_SEASONS)}): {len(test_df)} games")

    # 3. PREPARE MATRICES
    X_train, y_train = preprocess.get_features_and_labels(train_df, FEATURE_COLUMNS, TARGET_COL)
    X_val, y_val = preprocess.get_features_and_labels(test_df, FEATURE_COLUMNS, TARGET_COL)

    # 4. TRAIN MODEL
    print("\nTraining XGBoost Regressor...")
    model = xgb.XGBRegressor(
        objective='reg:squarederror',
        n_estimators=3000,
        learning_rate=0.005,
        max_depth=4,
        min_child_weight=3,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=-1,
        early_stopping_rounds=50
    )

    model.fit(
        X_train, y_train,
        eval_set=[(X_train, y_train), (X_val, y_val)],
        verbose=100
    )

    # 5. PREDICT & METRICS
    y_pred = model.predict(X_val)
    mae = mean_absolute_error(y_val, y_pred)
    rmse = np.sqrt(mean_squared_error(y_val, y_pred))
    
    print(f"\n--- PERFORMANCE METRICS (Seasons {TEST_SEASONS}) ---")
    print(f"MAE:  {mae:.2f} points")
    print(f"RMSE: {rmse:.2f} points")

    # 6. GENERATE PLOTS
    generate_plots(model, y_val, y_pred)

    # 7. RUN BETTING SIMULATION
    run_betting_simulation(test_df, y_pred, y_val)

def generate_plots(model, y_val, y_pred):
    print("\n--- GENERATING PLOTS ---")
    
    if not os.path.exists('Plots'):
        os.makedirs('Plots')

    # A. Learning Curve
    results = model.evals_result()
    epochs = len(results['validation_0']['rmse'])
    x_axis = range(0, epochs)
    
    plt.figure(figsize=(10, 6))
    plt.plot(x_axis, results['validation_0']['rmse'], label='Train')
    plt.plot(x_axis, results['validation_1']['rmse'], label='Validation')
    plt.legend()
    plt.ylabel('RMSE')
    plt.xlabel('Iterations')
    plt.title('XGBoost Learning Curve')
    plt.grid(True)
    plt.savefig('Plots/report_learning_curve.png')
    print("Saved Plots/report_learning_curve.png")

    # B. Scatter Plot
    plt.figure(figsize=(8, 8))
    plt.scatter(y_val, y_pred, alpha=0.5, color='blue')
    max_val = max(max(y_val), max(y_pred))
    min_val = min(min(y_val), min(y_pred))
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect')
    plt.xlabel('Actual')
    plt.ylabel('Predicted')
    plt.title('Predicted vs. Actual Scores')
    plt.legend()
    plt.grid(True)
    plt.savefig('Plots/report_scatter.png')
    print("Saved Plots/report_scatter.png")

    # C. Residuals
    residuals = y_val - y_pred
    plt.figure(figsize=(10, 6))
    sns.histplot(residuals, kde=True, bins=30, color='purple')
    plt.title('Residual Error Distribution')
    plt.xlabel('Error (Actual - Predicted)')
    plt.axvline(x=0, color='black', linestyle='--')
    plt.savefig('Plots/report_residuals.png')
    print("Saved Plots/report_residuals.png")

    # D. Feature Importance
    plt.figure(figsize=(10, 8))
    xgb.plot_importance(model, max_num_features=15)
    plt.title("Feature Importance")
    plt.tight_layout()
    plt.savefig('Plots/report_features.png')
    print("Saved Plots/report_features.png")

def run_betting_simulation(df, preds, actuals):
    print("\n--- BETTING SIMULATION ---")
    
    # Reconstruct DataFrame
    sim_df = df.copy()
    sim_df['Predicted_Total'] = preds
    sim_df['Actual_Total'] = actuals
    sim_df['Edge'] = sim_df['Predicted_Total'] - sim_df['total_line']
    
    # -----------------------------------------------------------
    # ADD WIN/LOSS COLUMNS FOR CSV EXPORT
    # -----------------------------------------------------------
    # 1. Determine Recommendation (Over/Under/Pass)
    def get_rec(edge):
        if edge > 0: return 'OVER'
        if edge < 0: return 'UNDER'
        return 'PASS'
    
    sim_df['Recommendation'] = sim_df['Edge'].apply(get_rec)

    # 2. Determine Result (Win/Loss/Push)
    def get_result(row):
        rec = row['Recommendation']
        actual = row['Actual_Total']
        line = row['total_line']
        
        if rec == 'PASS': return 'PUSH'
        
        if rec == 'OVER':
            if actual > line: return 'WIN'
            if actual < line: return 'LOSS'
            return 'PUSH'
            
        if rec == 'UNDER':
            if actual < line: return 'WIN'
            if actual > line: return 'LOSS'
            return 'PUSH'
            
        return 'ERROR'

    sim_df['Result'] = sim_df.apply(get_result, axis=1)

    # -----------------------------------------------------------
    # PRINT SUMMARY STATS
    # -----------------------------------------------------------
    thresholds = [0, 1, 2, 3, 4, 5]
    
    for t in thresholds:
        # Filter bets with enough edge
        active_bets = sim_df[abs(sim_df['Edge']) >= t]
        
        if len(active_bets) == 0:
            continue
            
        # Calculate Win Rate excluding Pushes
        decisive_bets = active_bets[active_bets['Result'] != 'PUSH']
        wins = decisive_bets[decisive_bets['Result'] == 'WIN']
        
        if len(decisive_bets) > 0:
            win_rate = len(wins) / len(decisive_bets)
            print(f"Edge > {t} pts: {len(active_bets)} bets ({len(decisive_bets)} decisive) | Win Rate: {win_rate*100:.2f}%")
        else:
            print(f"Edge > {t} pts: {len(active_bets)} bets | No decisive results")

    # Export detailed results including the new columns
    if not os.path.exists('Plots'):
        os.makedirs('Plots')
        
    export_cols = [
        'season', 'week', 'home_team', 'away_team', 
        'total_line', 'Predicted_Total', 'Actual_Total', 
        'Edge', 'Recommendation', 'Result'
    ]
    
    sim_df[export_cols].to_csv('Plots/simulation_results.csv', index=False)
    print("\nDetailed results (with Win/Loss columns) saved to Plots/simulation_results.csv")

if __name__ == "__main__":
    run_validation_suite()